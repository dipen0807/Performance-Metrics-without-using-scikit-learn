{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0Ej_bXyQvnV"
   },
   "source": [
    "# Compute performance metrics for the given Y and Y_score without sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CHb6NE7Qvnc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# other than these two you should not import any other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Section A:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbsWXuDaQvnq"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>A.</b></font> Compute performance metrics for the given data <strong>5_a.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)</li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WaFLW7oBQvnt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.637387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.635165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.766586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.889199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba  y_pred\n",
       "0  1.0  0.637387       1\n",
       "1  1.0  0.635165       1\n",
       "2  1.0  0.766586       1\n",
       "3  1.0  0.724564       1\n",
       "4  1.0  0.889199       1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"5_a.csv\")\n",
    "\n",
    "# Predicting y values\n",
    "y_predicted = [0 if i[2] < 0.5 else 1 for i in df.itertuples()]\n",
    "\n",
    "# Adding predicted values in dataframe in column \"y_pred\"\n",
    "df['y_pred'] = y_predicted\n",
    "\n",
    "# Checking the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: [[0, 0], [100, 10000]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Computing confusion matrix\n",
    "\n",
    "TN, FN, FP, TP = 0, 0, 0, 0\n",
    "\n",
    "# Iterating over rows of data-frame\n",
    "for i in df.itertuples():\n",
    "    if (i[1] == 0 and i[3] == 0):\n",
    "        TN += 1\n",
    "    elif (i[1] == 1 and i[3] == 0):\n",
    "        FN += 1\n",
    "    elif (i[1] == 0 and i[3] == 1):\n",
    "        FP += 1\n",
    "    else:\n",
    "        TP += 1\n",
    "        \n",
    "confusion_matrix = [[TN, FN],[FP, TP]]\n",
    "\n",
    "print(\"Confusion matrix:\", confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9950248756218906\n"
     ]
    }
   ],
   "source": [
    "# 2. Computing F1 score\n",
    "\n",
    "pr =  float(TP / (TP + FP))\n",
    "re = float(TP / (FN + TP))\n",
    "\n",
    "f1_score = 2 * ((pr * re) / (pr + re))\n",
    "print(\"F1 Score:\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC value is 0.48829900000000004\n"
     ]
    }
   ],
   "source": [
    "# 3. Computing AUC Score\n",
    "\n",
    "# Calculating FPR and TPR values\n",
    "def calculate_FPR_TPR_values(df):\n",
    "    FPR_values = []\n",
    "    TPR_values = []\n",
    "    \n",
    "    # Getting only unique probabilities for threshold in decreasing order\n",
    "    threshold_prob_scores = sorted(set(df[\"proba\"]), reverse=True)\n",
    "    \n",
    "    for value in threshold_prob_scores:\n",
    "        \n",
    "        # Predicting y values for every unique threshold value\n",
    "        y_hat = [1 if i[2] >= value else 0 for i in df.itertuples()]\n",
    "        \n",
    "        TN, FN, FP, TP = 0, 0, 0, 0\n",
    "        \n",
    "        # Computing confusion matrix values for every unique threshold value\n",
    "        for i, j in zip(df[\"y\"], y_hat):\n",
    "            if (i == 0 and j == 0):\n",
    "                TN += 1\n",
    "            elif (i == 1 and j == 0):\n",
    "                FN += 1\n",
    "            elif (i == 0 and j == 1):\n",
    "                FP += 1\n",
    "            else:\n",
    "                TP += 1\n",
    "    \n",
    "        FPR_values.append(float(FP / (TN + FP)))\n",
    "        TPR_values.append(float(TP / (FN + TP)))\n",
    "    \n",
    "    return (FPR_values, TPR_values)\n",
    "\n",
    "temp = calculate_FPR_TPR_values(df)\n",
    "print(\"The AUC value is\", np.trapz(temp[1], temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9900990099009901\n"
     ]
    }
   ],
   "source": [
    "# 4. Computing Accuracy\n",
    "\n",
    "print(\"Accuracy:\", float((TN + TP) / (TN + FN + FP + TP)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Section B:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V5KZem1BQvn2"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>B.</b></font> Compute performance metrics for the given data <strong>5_b.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a></li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2sKlq0YQvn5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba  y_pred\n",
       "0  0.0  0.281035       0\n",
       "1  0.0  0.465152       0\n",
       "2  0.0  0.352793       0\n",
       "3  0.0  0.157818       0\n",
       "4  0.0  0.276648       0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data\n",
    "df_2 = pd.read_csv(\"5_b.csv\")\n",
    "\n",
    "# Predicting y values\n",
    "y_predicted = [0 if i[2] < 0.5 else 1 for i in df_2.itertuples()]\n",
    "\n",
    "# Adding predicted values in dataframe in column \"y_pred\"\n",
    "df_2['y_pred'] = y_predicted\n",
    "\n",
    "# Checking the data\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: [[9761, 45], [239, 55]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Computing confusion matrix\n",
    "\n",
    "TN, FN, FP, TP = 0, 0, 0, 0\n",
    "\n",
    "# Iterating over rows of data-frame\n",
    "for i in df_2.itertuples():\n",
    "    if (i[1] == 0 and i[3] == 0):\n",
    "        TN += 1\n",
    "    elif (i[1] == 1 and i[3] == 0):\n",
    "        FN += 1\n",
    "    elif (i[1] == 0 and i[3] == 1):\n",
    "        FP += 1\n",
    "    else:\n",
    "        TP += 1\n",
    "\n",
    "confusion_matrix_2 = [[TN, FN],[FP, TP]]\n",
    "\n",
    "print(\"Confusion matrix:\", confusion_matrix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.2791878172588833\n"
     ]
    }
   ],
   "source": [
    "# 2. Computing F1 score\n",
    "\n",
    "pr =  float(TP / (TP + FP))\n",
    "re = float(TP / (FN + TP))\n",
    "\n",
    "f1_score = 2 * ((pr * re) / (pr + re))\n",
    "print(\"F1 Score:\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC value is 0.9377570000000001\n"
     ]
    }
   ],
   "source": [
    "# 3. Computing AUC Score\n",
    "\n",
    "# Calculating FPR and TPR values\n",
    "def calculate_FPR_TPR_values(df):\n",
    "    FPR_values = []\n",
    "    TPR_values = []\n",
    "    \n",
    "    # Getting only unique probabilities for threshold in decreasing order\n",
    "    threshold_prob_scores = sorted(set(df[\"proba\"]), reverse=True)\n",
    "    \n",
    "    for value in threshold_prob_scores:\n",
    "        \n",
    "        # Predicting y values for every unique threshold value\n",
    "        y_hat = [1 if i[2] >= value else 0 for i in df.itertuples()]\n",
    "        \n",
    "        TN, FN, FP, TP = 0, 0, 0, 0\n",
    "        \n",
    "        # Computing confusion matrix values for every unique threshold value\n",
    "        for i, j in zip(df[\"y\"], y_hat):\n",
    "            if (i == 0 and j == 0):\n",
    "                TN += 1\n",
    "            elif (i == 1 and j == 0):\n",
    "                FN += 1\n",
    "            elif (i == 0 and j == 1):\n",
    "                FP += 1\n",
    "            else:\n",
    "                TP += 1\n",
    "    \n",
    "        FPR_values.append(float(FP / (TN + FP)))\n",
    "        TPR_values.append(float(TP / (FN + TP)))\n",
    "    \n",
    "    return (FPR_values, TPR_values)\n",
    "\n",
    "temp = calculate_FPR_TPR_values(df_2)\n",
    "print(\"The AUC value is\", np.trapz(temp[1], temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9718811881188119\n"
     ]
    }
   ],
   "source": [
    "# 4. Computing Accuracy\n",
    "\n",
    "print(\"Accuracy:\", float((TN + TP) / (TN + FN + FP + TP)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Section C:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GiPGonTzQvoB"
   },
   "source": [
    "<font color='red'><b>C.</b></font> Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data <strong>5_c.csv</strong>\n",
    "<br>\n",
    "\n",
    "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
    "\n",
    "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
    "\n",
    "<pre>\n",
    "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5HIJzq1QvoE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.458521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.505037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.418652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.412057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.375579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y      prob\n",
       "0  0  0.458521\n",
       "1  0  0.505037\n",
       "2  0  0.418652\n",
       "3  0  0.412057\n",
       "4  0  0.375579"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data\n",
    "df_3 = pd.read_csv(\"5_c.csv\")\n",
    "\n",
    "# Checking the data\n",
    "df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best threshold of probability which gives lowest values of metric A is 0.230039028\n"
     ]
    }
   ],
   "source": [
    "prob_metA_dict = dict()\n",
    "\n",
    "# Getting only unique probabilities for threshold in decreasing order\n",
    "threshold_prob_scores = sorted(set(df_3[\"prob\"]), reverse=True)\n",
    "\n",
    "for value in threshold_prob_scores:\n",
    "    \n",
    "    # Predicting y values for every unique threshold value\n",
    "    y_hat = [1 if i[2] >= value else 0 for i in df_3.itertuples()]\n",
    "        \n",
    "    FN, FP = 0, 0\n",
    "    \n",
    "    for i, j in zip(df_3[\"y\"], y_hat):\n",
    "        if (i == 1 and j == 0):\n",
    "            FN += 1\n",
    "        if (i == 0 and j == 1):\n",
    "            FP += 1\n",
    "    \n",
    "    # Calculating metric A's value for every unique threshold value's FN and FP values\n",
    "    A = (500 * FN) + (100 * FP)\n",
    "    \n",
    "    # Making a dictionary with threshold prob values as \"key\" and its metric A's value as \"value\"\n",
    "    prob_metA_dict[value] = A\n",
    "\n",
    "# Finding the minimum value of metric A\n",
    "temp = min(prob_metA_dict.values())\n",
    "\n",
    "# For the minimum value of metric A, finding the adjacent threshold probability value\n",
    "for k, v in prob_metA_dict.items():\n",
    "    if v == temp:\n",
    "        print(\"The best threshold of probability which gives lowest values of metric A is\", k)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Section D:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sD4CcgjXQvoL"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>D.</b></font> Compute performance metrics(for regression) for the given data <strong>5_d.csv</strong>\n",
    "    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
    "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
    "<ol>\n",
    "<li> Compute Mean Square Error </li>\n",
    "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
    "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y   pred\n",
       "0  101.0  100.0\n",
       "1  120.0  100.0\n",
       "2  131.0  113.0\n",
       "3  164.0  125.0\n",
       "4  154.0  152.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data\n",
    "df_4 = pd.read_csv(\"5_d.csv\")\n",
    "\n",
    "# Checking the data\n",
    "df_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Square Error is 177.17\n"
     ]
    }
   ],
   "source": [
    "# 1. Computing Mean Square Error\n",
    "\n",
    "sum = 0\n",
    "\n",
    "# Iterating over rows of data-frame\n",
    "for i in df_4.itertuples():\n",
    "    sum = sum + pow((i[1]-i[2]),2)\n",
    "    \n",
    "print(\"The Mean Square Error is\", round((sum/len(df_4)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Absolute Percentage Error is 12.91 %\n"
     ]
    }
   ],
   "source": [
    "# 2. Computing MAPE\n",
    "\n",
    "sum_e = 0\n",
    "sum_y = 0\n",
    "\n",
    "# Iterating over rows of data-frame\n",
    "for i in df_4.itertuples():\n",
    "    \n",
    "    # Finding sum of absolute errors\n",
    "    sum_e = sum_e + abs(i[1]-i[2])\n",
    "    \n",
    "    # Finding sum of actual values\n",
    "    sum_y = sum_y + i[1]\n",
    "    \n",
    "print(\"The Mean Absolute Percentage Error is {0} %\".format(round(float(sum_e/sum_y)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 error is 0.96\n"
     ]
    }
   ],
   "source": [
    "# 3. Computing R^2 error\n",
    "\n",
    "SS_res = 0\n",
    "SS_tot = 0\n",
    "sum_y = 0\n",
    "\n",
    "# Iterating over rows of data-frame\n",
    "for i in df_4.itertuples():\n",
    "    \n",
    "    # Finding sum of actual values\n",
    "    sum_y = sum_y + i[1]\n",
    "\n",
    "# Finding mean of actual values\n",
    "y_mean = float(sum_y/len(df_4))\n",
    "\n",
    "# Iterating over rows of data-frame\n",
    "for i in df_4.itertuples():\n",
    "    SS_res = SS_res + pow((i[1]-i[2]),2)\n",
    "    SS_tot = SS_tot + pow((i[1]-y_mean),2)\n",
    "    \n",
    "print(\"R^2 error is\", round(float(1-(SS_res/SS_tot)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5_Performance_metrics_Instructions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
